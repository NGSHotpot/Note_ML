# HIVE常见问题及其解决方法
##### 有个HIVE调度任务运行时间特别长：
**问题状态：** 未解决
**背景：**HDFS对文件进行了压缩，而且不添加索引。主要用HIVE进行开发。
**发现的现象：**sqoop从Mysql导入数据，根据ID进行平均分割,但是ID分部及其不均匀(我也不知道业务系统怎么搞得)。所以导致reduce出来的文件大小严重不均匀，就是所谓的数据倾斜。
导致的问题：写HQL从该表中读取数据，发现整个job很慢。后来我查日志发现，有几个map读取数据非常慢，1G的文件大概需要1个多小时才能读取完毕。
**问题分析：** 由于hadoop对文件进行了lzo格式压缩（lzo格式不支持切割）。运维又没有对文件添加索引，所以这1G的文件必须走一次网络I/O将文件读取到map所在节点，然后再整体读取。所以导致该map非常慢。
**解决思路：** 
    1. 将Mysql中的数据用sqoop分批导入HIVE，高密度的ID一个任务，低密度的ID一个任务（我前后分了5个任务,效果显著，但是还是没有达到理想效果）。控制每个文件大小在1G一下。
    2. 通过设置HIVE参数和拆分复杂的HQL，将大文件分割成均匀的小文件。目前还正在解决......
